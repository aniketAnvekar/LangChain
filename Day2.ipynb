{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced LangChain Tutorial: Structured Outputs & Agents\n",
    "\n",
    "This notebook covers advanced LangChain features:\n",
    "- **Structured Outputs** with TypedDict and Pydantic models\n",
    "- **Nested Data Structures** for complex responses\n",
    "- **Agent Workflows** with tools and middleware\n",
    "- **Memory Management** with checkpointers\n",
    "- **Human-in-the-Loop** review workflows\n",
    "- **Email Generation** with SMTP integration\n",
    "- **Token Counting** and optimization\n",
    "- **Production-Ready Patterns** for real-world applications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "Install required packages:\n",
    "```bash\n",
    "pip install langchain-anthropic langchain-ollama python-dotenv langchain langchain-core pydantic typing-extensions langgraph\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import List, Literal\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import SummarizationMiddleware\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "Set up the model with support for both Anthropic and Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized: Ollama\n"
     ]
    }
   ],
   "source": [
    "# Choose your model provider\n",
    "USE_OLLAMA = True  # Set to True for Ollama, False for Anthropic\n",
    "\n",
    "if USE_OLLAMA:\n",
    "    model = ChatOllama(\n",
    "        model=\"llama3.2\",\n",
    "        base_url=os.getenv(\"OLLAMA_BASE_URL\", \"http://localhost:11434\"),\n",
    "        temperature=0.7,\n",
    "    )\n",
    "else:\n",
    "    model = ChatAnthropic(\n",
    "        model=\"claude-3-5-sonnet-20241022\",\n",
    "        temperature=0.7,\n",
    "        max_tokens=4000,\n",
    "        api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    )\n",
    "\n",
    "print(f\"Model initialized: {'Ollama' if USE_OLLAMA else 'Anthropic Claude'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Structured Outputs with TypedDict\n",
    "\n",
    "## Overview\n",
    "Structured outputs ensure the LLM returns data in a specific format using TypedDict or Pydantic models. This is essential for:\n",
    "- Type safety\n",
    "- Validation\n",
    "- Integration with downstream systems\n",
    "- Consistent data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Movie Details with TypedDict\n",
    "\n",
    "Define structured response formats using TypedDict for movie information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': 'Better Call Saul', 'director': 'Vince Gilligan and Peter Gould', 'year': 2015, 'genre': 'Crime, Drama', 'rating': 9.1, 'actors': [{'name': 'Bob Odenkirk', 'age': 57}, {'name': 'Jonathan Banks', 'age': 73}]}\n"
     ]
    }
   ],
   "source": [
    "# Define Actor structure using TypedDict\n",
    "class Actor(TypedDict):\n",
    "    \"\"\"Actor information in a movie\"\"\"\n",
    "    name: Annotated[str, \"The name of the actor\"]\n",
    "    age: Annotated[int, \"The age of the actor\"]\n",
    "    awards: Annotated[int, \"Number of awards won by the actor\"]\n",
    "\n",
    "# Define MovieDetails structure\n",
    "class MovieDetails(TypedDict):\n",
    "    \"\"\"Complete movie information\"\"\"\n",
    "    title: Annotated[str, \"The title of the movie\"]\n",
    "    director: Annotated[str, \"The director of the movie\"]\n",
    "    year: Annotated[int, \"The release year of the movie\"]\n",
    "    genre: Annotated[str, \"The genre of the movie\"]\n",
    "    rating: Annotated[float, \"The IMDb rating of the movie\"]\n",
    "    actors: Annotated[List[Actor], \"List of main actors in the movie\"]\n",
    "\n",
    "# Bind the structured output to the model\n",
    "model_with_nested_typed_dict_output = model.with_structured_output(MovieDetails)\n",
    "\n",
    "# Invoke the model\n",
    "response = model_with_nested_typed_dict_output.invoke(\n",
    "    \"Provide detailed information about the web series 'Better Call Saul', including main actors.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding TypedDict vs Pydantic\n",
    "\n",
    "**TypedDict:**\n",
    "- Lightweight type hints for dictionaries\n",
    "- No runtime validation\n",
    "- Part of Python's typing module\n",
    "- Best for simple structures\n",
    "\n",
    "**Pydantic:**\n",
    "- Full data validation at runtime\n",
    "- Rich feature set (default values, validators, etc.)\n",
    "- Better error messages\n",
    "- Best for complex, validated data structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Structured Outputs with Pydantic\n",
    "\n",
    "Pydantic provides more robust data validation and better developer experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Movie Details with Pydantic BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Movie structure using Pydantic\n",
    "class Movie(BaseModel):\n",
    "    \"\"\"Movie model with validation\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    year: int = Field(..., description=\"The release year of the movie\")\n",
    "    genre: str = Field(..., description=\"The genre of the movie\")\n",
    "    rating: float = Field(..., description=\"The IMDb rating of the movie\")\n",
    "\n",
    "# Define Actor structure using Pydantic\n",
    "class Actor(BaseModel):\n",
    "    \"\"\"Actor model with validation\"\"\"\n",
    "    name: str = Field(..., description=\"The name of the actor\")\n",
    "    age: int = Field(..., description=\"The age of the actor\")\n",
    "    awards: int = Field(..., description=\"Number of awards won by the actor\")\n",
    "\n",
    "# Define MovieDetails with nested Actor list\n",
    "class MovieDetails(BaseModel):\n",
    "    \"\"\"Complete movie details with actors\"\"\"\n",
    "    title: str = Field(..., description=\"The title of the movie\")\n",
    "    director: str = Field(..., description=\"The director of the movie\")\n",
    "    year: int = Field(..., description=\"The release year of the movie\")\n",
    "    genre: str = Field(..., description=\"The genre of the movie\")\n",
    "    rating: float = Field(..., description=\"The IMDb rating of the movie\")\n",
    "    actors: List[Actor] = Field(..., description=\"List of main actors in the movie\")\n",
    "\n",
    "# Bind Pydantic model to the LLM\n",
    "model_with_nested_output = model.with_structured_output(MovieDetails)\n",
    "\n",
    "# Get structured response\n",
    "response = model_with_nested_output.invoke(\n",
    "    \"Provide detailed information about the web series 'Better Call Saul', including main actors.\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Contact Information Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Agent Result ===\n",
      "{'messages': [HumanMessage(content='Collect contact info for John Doe, email john.doe@example.com, phone 123-456-7890', additional_kwargs={}, response_metadata={}, id='7e74b608-69bf-4834-8f36-9ae4c4a81793'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2026-02-01T22:57:18.468668Z', 'done': True, 'done_reason': 'stop', 'total_duration': 3371601208, 'load_duration': 23901583, 'prompt_eval_count': 217, 'prompt_eval_duration': 1948000000, 'eval_count': 39, 'eval_duration': 1142000000, 'logprobs': None, 'model_name': 'llama3.2', 'model_provider': 'ollama'}, id='lc_run--019c1b6c-b54f-7122-8112-b4b4a32d9510-0', tool_calls=[{'name': 'ContactInfo', 'args': {'email': 'john.doe@example.com', 'name': 'John Doe', 'phone': '123-456-7890'}, 'id': 'fbc57da4-94cc-469d-a947-f38b9c9f818a', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 217, 'output_tokens': 39, 'total_tokens': 256}), ToolMessage(content=\"Returning structured response: name='John Doe' email='john.doe@example.com' phone='123-456-7890'\", name='ContactInfo', id='2b9a2351-ed87-41c9-a421-40e22813e010', tool_call_id='fbc57da4-94cc-469d-a947-f38b9c9f818a')], 'structured_response': ContactInfo(name='John Doe', email='john.doe@example.com', phone='123-456-7890')}\n",
      "\n",
      "=== Extracted Contact Info ===\n",
      "name='John Doe' email='john.doe@example.com' phone='123-456-7890'\n"
     ]
    }
   ],
   "source": [
    "# Define ContactInfo Pydantic model\n",
    "class ContactInfo(BaseModel):\n",
    "    \"\"\"Contact information structure\"\"\"\n",
    "    name: str = Field(..., description=\"Full name of the contact\")\n",
    "    email: str = Field(..., description=\"Email address of the contact\")\n",
    "    phone: str = Field(..., description=\"Phone number of the contact\")\n",
    "\n",
    "# Create an agent that collects contact information\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a helpful assistant that collects contact information.\",\n",
    "    response_format=ContactInfo\n",
    ")\n",
    "\n",
    "# Invoke the agent\n",
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Collect contact info for John Doe, email john.doe@example.com, phone 123-456-7890\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\\n=== Agent Result ===\")\n",
    "print(result)\n",
    "\n",
    "# Access structured response\n",
    "print(\"\\n=== Extracted Contact Info ===\")\n",
    "print(result['structured_response'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Agent Middleware - Summarization\n",
    "\n",
    "## What is Middleware?\n",
    "Middleware intercepts and processes messages between the user and the agent. Common uses:\n",
    "- **Summarization**: Condense long conversation histories\n",
    "- **Translation**: Convert between languages\n",
    "- **Filtering**: Remove sensitive information\n",
    "- **Logging**: Track conversations\n",
    "\n",
    "## SummarizationMiddleware\n",
    "Keeps conversation context manageable by summarizing old messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check SummarizationMiddleware signature\n",
    "print(SummarizationMiddleware.__init__.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Advanced Agent with Tools and Middleware\n",
    "\n",
    "Build a production-ready financial analysis agent with:\n",
    "- Custom tools for ETF search\n",
    "- Structured output (Pydantic models)\n",
    "- Memory management\n",
    "- Conversation summarization\n",
    "- Token counting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Pydantic Models for Financial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETF Analysis model\n",
    "class ETFAnalysis(BaseModel):\n",
    "    \"\"\"Structured ETF analysis with required financial metrics.\"\"\"\n",
    "    etf_name: str = Field(..., description=\"ETF ticker (e.g., VOO)\")\n",
    "    one_year_return: float = Field(..., ge=0, description=\"1-year return percentage\")\n",
    "    five_year_return: float = Field(..., ge=0, description=\"5-year annualized return percentage\")\n",
    "    revenue_2023: float = Field(..., ge=0, description=\"Revenue for 2023 ($M)\")\n",
    "    revenue_2022: float = Field(..., ge=0, description=\"Revenue for 2022 ($M)\")\n",
    "    revenue_2021: float = Field(..., ge=0, description=\"Revenue for 2021 ($M)\")\n",
    "    total_assets: float = Field(..., ge=0, description=\"Total assets under management ($B)\")\n",
    "\n",
    "# Top 3 ETFs per company\n",
    "class TopETFsAnalysis(BaseModel):\n",
    "    \"\"\"Top 3 ETFs per company.\"\"\"\n",
    "    company: str = Field(..., description=\"Company name\")\n",
    "    etf_1: ETFAnalysis = Field(..., description=\"Rank 1 ETF\")\n",
    "    etf_2: ETFAnalysis = Field(..., description=\"Rank 2 ETF\")\n",
    "    etf_3: ETFAnalysis = Field(..., description=\"Rank 3 ETF\")\n",
    "\n",
    "# Email content model\n",
    "class EmailContent(BaseModel):\n",
    "    \"\"\"Email content for human review.\"\"\"\n",
    "    subject: str = Field(..., description=\"Email subject line\")\n",
    "    body: str = Field(..., description=\"Email body content\")\n",
    "    recipient: str = Field(..., description=\"Recipient email address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define ETF Search Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_etfs(company: str) -> str:\n",
    "    \"\"\"Search top performing ETFs for the company. Returns ticker symbols.\"\"\"\n",
    "    # Simulated ETF database\n",
    "    etfs = \"VOO, VTI, SCHB, SPY, QQQ, VUG, VYM, FNCL, FTEC, XLK, XLF, SCHX, SCHD, IVV, IWF, RSP, ITOT\"\n",
    "    return f\"Top ETFs for {company}: {etfs}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Counting for Production Use\n",
    "\n",
    "Token counting is critical for:\n",
    "- Cost management\n",
    "- Context window optimization\n",
    "- Performance monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_token_counter(model):\n",
    "    \"\"\"Factory function to create token counter with model in closure.\"\"\"\n",
    "    \n",
    "    def count_tokens(messages):\n",
    "        \"\"\"Token counter for middleware - only takes messages parameter.\"\"\"\n",
    "        try:\n",
    "            # Try to use the model's built-in token counting method\n",
    "            return model.get_num_tokens_from_messages(messages)\n",
    "        except:\n",
    "            # Fallback 1: Character-based estimation (accurate enough for most cases)\n",
    "            total_chars = sum(len(str(getattr(m, 'content', ''))) for m in messages)\n",
    "            return total_chars // 4 + 100  # ~4 chars per token + padding for headers/metadata\n",
    "    \n",
    "    return count_tokens\n",
    "\n",
    "# Create the token counter for this model\n",
    "token_counter = make_token_counter(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Production Agent with All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: Structured outputs work differently for Anthropic vs Ollama\n",
    "# - Anthropic: Native structured output support\n",
    "# - Ollama: Returns text/code that needs parsing\n",
    "\n",
    "if USE_OLLAMA:\n",
    "    # For Ollama: Use simple agent without structured output\n",
    "    # We'll parse the response manually\n",
    "    agent = create_agent(\n",
    "        model=model,\n",
    "        tools=[search_etfs],\n",
    "        system_prompt=\"\"\"Financial analyst. You MUST respond with ONLY a JSON object in this exact format:\n",
    "{\n",
    "  \"company\": \"CompanyName\",\n",
    "  \"etf_1\": {\"etf_name\": \"VOO\", \"one_year_return\": 15.5, \"five_year_return\": 75.2, \"revenue_2023\": 1000.0, \"revenue_2022\": 950.0, \"revenue_2021\": 900.0, \"total_assets\": 500.5},\n",
    "  \"etf_2\": {\"etf_name\": \"VTI\", \"one_year_return\": 14.2, \"five_year_return\": 72.1, \"revenue_2023\": 800.0, \"revenue_2022\": 750.0, \"revenue_2021\": 700.0, \"total_assets\": 400.3},\n",
    "  \"etf_3\": {\"etf_name\": \"SPY\", \"one_year_return\": 13.8, \"five_year_return\": 70.5, \"revenue_2023\": 600.0, \"revenue_2022\": 550.0, \"revenue_2021\": 500.0, \"total_assets\": 300.2}\n",
    "}\n",
    "\n",
    "Process:\n",
    "1. Call search_etfs tool FIRST\n",
    "2. Pick EXACTLY 3 different ETFs from results\n",
    "3. Provide realistic metrics for each\n",
    "4. Return ONLY the JSON, no explanation\"\"\",\n",
    "        checkpointer=MemorySaver(),\n",
    "    )\n",
    "else:\n",
    "    # For Anthropic: Use native structured output\n",
    "    agent = create_agent(\n",
    "        model=model,\n",
    "        tools=[search_etfs],\n",
    "        system_prompt=\"\"\"Financial analyst. Process:\n",
    "1. Call search_etfs FIRST\n",
    "2. Pick EXACTLY top 3 ETFs from results\n",
    "3. Realistic metrics: 1yr/5yr returns, revenue 2021-23, AUM\n",
    "4. Return TopETFsAnalysis (etf_1, etf_2, etf_3 exactly)\n",
    "Concise.\"\"\",\n",
    "        checkpointer=MemorySaver(),\n",
    "        response_format=TopETFsAnalysis,  # Structured output\n",
    "        middleware=[\n",
    "            SummarizationMiddleware(\n",
    "                model=model,\n",
    "                max_tokens_before_summary=900,\n",
    "                messages_to_keep=10,\n",
    "                token_counter=token_counter\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Configuration for threading\n",
    "config = {\"configurable\": {\"thread_id\": \"etf-final-v1\"}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Function: Parse Agent Response\n",
    "\n",
    "Handle responses differently based on model provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_agent_response(response, use_ollama=False):\n",
    "    \"\"\"\n",
    "    Parse agent response for both Anthropic and Ollama.\n",
    "    \n",
    "    Args:\n",
    "        response: Agent response dict\n",
    "        use_ollama: Whether using Ollama (needs JSON parsing)\n",
    "    \n",
    "    Returns:\n",
    "        TopETFsAnalysis object\n",
    "    \"\"\"\n",
    "    if not use_ollama:\n",
    "        # Anthropic: Direct structured response\n",
    "        return response[\"structured_response\"]\n",
    "    \n",
    "    # Ollama: Parse JSON from text response\n",
    "    messages = response.get(\"messages\", [])\n",
    "    if not messages:\n",
    "        raise ValueError(\"No messages in response\")\n",
    "    \n",
    "    # Get the last AI message\n",
    "    last_message = None\n",
    "    for msg in reversed(messages):\n",
    "        if hasattr(msg, 'content') and msg.content:\n",
    "            last_message = msg.content\n",
    "            break\n",
    "    \n",
    "    if not last_message:\n",
    "        raise ValueError(\"No content in response\")\n",
    "    \n",
    "    # Extract JSON from response (may be wrapped in code blocks or text)\n",
    "    # Try to find JSON object\n",
    "    json_match = re.search(r'\\{[^{}]*\"company\"[^{}]*\\{.*?\\}.*?\\{.*?\\}.*?\\{.*?\\}.*?\\}', last_message, re.DOTALL)\n",
    "    \n",
    "    if json_match:\n",
    "        json_str = json_match.group(0)\n",
    "        try:\n",
    "            data = json.loads(json_str)\n",
    "            # Convert to TopETFsAnalysis\n",
    "            return TopETFsAnalysis(**data)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSON parse error: {e}\")\n",
    "            print(f\"Attempted to parse: {json_str[:200]}...\")\n",
    "    \n",
    "    # Fallback: Create mock data if parsing fails\n",
    "    print(\"âš ï¸ Warning: Could not parse structured response, using mock data\")\n",
    "    return TopETFsAnalysis(\n",
    "        company=\"Unknown\",\n",
    "        etf_1=ETFAnalysis(\n",
    "            etf_name=\"VOO\",\n",
    "            one_year_return=15.5,\n",
    "            five_year_return=75.0,\n",
    "            revenue_2023=1000.0,\n",
    "            revenue_2022=950.0,\n",
    "            revenue_2021=900.0,\n",
    "            total_assets=500.0\n",
    "        ),\n",
    "        etf_2=ETFAnalysis(\n",
    "            etf_name=\"VTI\",\n",
    "            one_year_return=14.0,\n",
    "            five_year_return=72.0,\n",
    "            revenue_2023=800.0,\n",
    "            revenue_2022=750.0,\n",
    "            revenue_2021=700.0,\n",
    "            total_assets=400.0\n",
    "        ),\n",
    "        etf_3=ETFAnalysis(\n",
    "            etf_name=\"SPY\",\n",
    "            one_year_return=13.0,\n",
    "            five_year_return=70.0,\n",
    "            revenue_2023=600.0,\n",
    "            revenue_2022=550.0,\n",
    "            revenue_2021=500.0,\n",
    "            total_assets=300.0\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Financial Analysis for Multiple Companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” TOP 3 ETFs ANALYSIS (6 Companies = 18 ETFs)\n",
      "==========================================================================================\n",
      "\n",
      "ğŸ“Š Analyzing Vanguard...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aniketanvekar/Documents/LangChain/LangChain/.venv/lib/python3.11/site-packages/langchain_core/language_models/base.py:328: UserWarning: Using fallback GPT-2 tokenizer for token counting. Token counts may be inaccurate for non-GPT-2 models. For accurate counts, use a model-specific method if available.\n",
      "  return len(self.get_token_ids(text))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ SCHB   | 1yr: 12.8% 5yr: 68.4% AUM:$  200.5B\n",
      "  ğŸ“Š Tokens: ~291 (msgs: 4)\n",
      "\n",
      "ğŸ“Š Analyzing Fidelity...\n",
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ FTEC   | 1yr: 10.5% 5yr: 63.4% AUM:$  150.2B\n",
      "  ğŸ“Š Tokens: ~483 (msgs: 8)\n",
      "\n",
      "ğŸ“Š Analyzing State Street...\n",
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ SPY    | 1yr: 13.8% 5yr: 70.5% AUM:$  300.2B\n",
      "  ğŸ“Š Tokens: ~678 (msgs: 12)\n",
      "\n",
      "ğŸ“Š Analyzing Charles Schwab...\n",
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ SCHB   | 1yr: 12.8% 5yr: 68.4% AUM:$  200.5B\n",
      "  ğŸ“Š Tokens: ~874 (msgs: 16)\n",
      "\n",
      "ğŸ“Š Analyzing Invesco...\n",
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ VYM    | 1yr: 12.8% 5yr: 68.4% AUM:$  250.2B\n",
      "  ğŸ“Š Tokens: ~1065 (msgs: 20)\n",
      "\n",
      "ğŸ“Š Analyzing Blackrock...\n",
      "  ğŸ“ˆ VOO    | 1yr: 15.5% 5yr: 75.2% AUM:$  500.5B\n",
      "  ğŸ“ˆ VTI    | 1yr: 14.2% 5yr: 72.1% AUM:$  400.3B\n",
      "  ğŸ“ˆ BLK    | 1yr: 13.9% 5yr: 69.4% AUM:$  300.5B\n",
      "  ğŸ“Š Tokens: ~1257 (msgs: 24)\n"
     ]
    }
   ],
   "source": [
    "# List of companies to analyze\n",
    "companies = [\"Vanguard\", \"Fidelity\", \"State Street\", \"Charles Schwab\", \"Invesco\", \"Blackrock\"]\n",
    "\n",
    "print(\"ğŸ” TOP 3 ETFs ANALYSIS (6 Companies = 18 ETFs)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for company in companies:\n",
    "    print(f\"\\nğŸ“Š Analyzing {company}...\")\n",
    "    \n",
    "    # Invoke agent for this company\n",
    "    response = agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f\"Analyze top ETFs from {company}: provide ETF name, 1yr/5yr returns, revenue past 3 years, total assets\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    # Parse response (handles both Anthropic and Ollama)\n",
    "    try:\n",
    "        analysis = parse_agent_response(response, use_ollama=USE_OLLAMA)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error parsing response for {company}: {e}\")\n",
    "        print(f\"Response keys: {response.keys()}\")\n",
    "        continue\n",
    "    \n",
    "    tokens = token_counter(response.get(\"messages\", []))\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_1.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_1.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_1.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_1.total_assets:7.1f}B\")\n",
    "    \n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_2.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_2.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_2.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_2.total_assets:7.1f}B\")\n",
    "    \n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_3.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_3.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_3.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_3.total_assets:7.1f}B\")\n",
    "    \n",
    "    print(f\"  ğŸ“Š Tokens: ~{tokens} (msgs: {len(response['messages'])})\")\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'company': analysis.company,\n",
    "        'etf1': analysis.etf_1.model_dump(),  # Fixed: Pydantic V2\n",
    "        'etf2': analysis.etf_2.model_dump(),  # Fixed: Pydantic V2\n",
    "        'etf3': analysis.etf_3.model_dump(),  # Fixed: Pydantic V2\n",
    "        'tokens': tokens\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“Š SUMMARY | TOP 3 ETFs | 6 COMPANIES | 18 TOTAL\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"{'Company'.ljust(13)}|{'ETF1'.ljust(8)}|{'1yr'.ljust(6)}|\\n\"\n",
    "      f\"{'ETF2'.ljust(8)}|{'1yr'.ljust(6)}|\\n\"\n",
    "      f\"{'ETF3'.ljust(8)}|{'Tokens'}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for r in all_results:\n",
    "    e1, e2, e3 = r['etf1'], r['etf2'], r['etf3']\n",
    "    print(f\"{r['company'].ljust(13)}|{e1['etf_name'].ljust(8)}|{e1['one_year_return']:5.1f}%|\\n\"\n",
    "          f\"{e2['etf_name'].ljust(8)}|{e2['one_year_return']:5.1f}%|\\n\"\n",
    "          f\"{e3['etf_name'].ljust(8)}|{r['tokens']:5d}\")\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Results to Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to Pandas DataFrame and CSV\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\nâœ… PERFECT! Data ready in 'all_results'\")\n",
    "print(\"ğŸ“Š Pandas: pd.DataFrame([{**r, 'all_etfs':[r['etf1'],r['etf2'],r['etf3']]} for r in all_results])\")\n",
    "print(\"ğŸ’¾ CSV: df.to_csv('top3_etfs_6companies.csv')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 5: Human-in-the-Loop Email Workflow\n",
    "\n",
    "## Why Human-in-the-Loop?\n",
    "For sensitive operations like sending emails, human review ensures:\n",
    "- Content accuracy\n",
    "- Tone appropriateness\n",
    "- Compliance with policies\n",
    "- Error prevention\n",
    "\n",
    "This pattern is essential for production AI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Email Content Generation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_email_content(analysis: TopETFsAnalysis, recipient: str) -> EmailContent:\n",
    "    \"\"\"Generate email content from ETF analysis.\"\"\"\n",
    "    subject = f\"Top 3 ETF Recommendations from {analysis.company}\"\n",
    "    \n",
    "    body = f\"\"\"\n",
    "Dear Investor,\n",
    "\n",
    "Based on our AI-powered analysis, here are the top 3 ETF recommendations from {analysis.company}:\n",
    "\n",
    "ğŸ”¥ #{1} - {analysis.etf_1.etf_name}\n",
    "   â€¢ 1-Year Return: {analysis.etf_1.one_year_return:.1f}%\n",
    "   â€¢ 5-Year Return: {analysis.etf_1.five_year_return:.1f}%\n",
    "   â€¢ Assets Under Management: ${analysis.etf_1.total_assets:.1f}B\n",
    "   â€¢ Revenue (2023): ${analysis.etf_1.revenue_2023:.0f}M\n",
    "\n",
    "ğŸ”¥ #{2} - {analysis.etf_2.etf_name}\n",
    "   â€¢ 1-Year Return: {analysis.etf_2.one_year_return:.1f}%\n",
    "   â€¢ 5-Year Return: {analysis.etf_2.five_year_return:.1f}%\n",
    "   â€¢ Assets Under Management: ${analysis.etf_2.total_assets:.1f}B\n",
    "   â€¢ Revenue (2023): ${analysis.etf_2.revenue_2023:.0f}M\n",
    "\n",
    "ğŸ”¥ #{3} - {analysis.etf_3.etf_name}\n",
    "   â€¢ 1-Year Return: {analysis.etf_3.one_year_return:.1f}%\n",
    "   â€¢ 5-Year Return: {analysis.etf_3.five_year_return:.1f}%\n",
    "   â€¢ Assets Under Management: ${analysis.etf_3.total_assets:.1f}B\n",
    "   â€¢ Revenue (2023): ${analysis.etf_3.revenue_2023:.0f}M\n",
    "\n",
    "---\n",
    "This analysis was generated by our AI financial advisor.\n",
    "Please consult with a financial professional before making investment decisions.\n",
    "\n",
    "Best regards,\n",
    "Investment Analysis Team\n",
    "\"\"\"\n",
    "    \n",
    "    return EmailContent(subject=subject, body=body, recipient=recipient)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Human Review Function\n",
    "\n",
    "Interactive function that allows humans to:\n",
    "- Approve email for sending\n",
    "- Edit subject or body\n",
    "- Reject email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_review_email(email_content: EmailContent) -> tuple[bool, EmailContent]:\n",
    "    \"\"\"\n",
    "    Display email to human reviewer and get approval.\n",
    "    Returns: (approved: bool, modified_email: EmailContent)\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“§ EMAIL REVIEW - HUMAN APPROVAL REQUIRED\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nğŸ“§ TO: {email_content.recipient}\")\n",
    "    print(f\"ğŸ“§ SUBJECT: {email_content.subject}\")\n",
    "    print(f\"\\nğŸ“§ BODY:\\n{email_content.body}\")\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    \n",
    "    # Get human approval\n",
    "    while True:\n",
    "        decision = input(\n",
    "            \"\\nğŸ¤” Review Decision:\\n [A]pprove [E]dit [R]eject\\nYour choice: \"\n",
    "        ).strip().upper()\n",
    "        \n",
    "        if decision == 'A':\n",
    "            print(\"âœ… Email APPROVED for sending!\")\n",
    "            return True, email_content\n",
    "        \n",
    "        elif decision == 'E':\n",
    "            print(\"\\nğŸ“ Edit Mode:\")\n",
    "            new_subject = input(\n",
    "                f\"New Subject (press Enter to keep '{email_content.subject}'): \"\n",
    "            ).strip()\n",
    "            new_body = input(\n",
    "                f\"New Body (press Enter to keep current): \"\n",
    "            ).strip()\n",
    "            \n",
    "            if new_subject:\n",
    "                email_content.subject = new_subject\n",
    "            if new_body:\n",
    "                email_content.body = new_body\n",
    "            \n",
    "            print(\"ğŸ“§ Email updated! Showing revised version...\")\n",
    "            return human_review_email(email_content)  # Recursive review\n",
    "        \n",
    "        elif decision == 'R':\n",
    "            print(\"âŒ Email REJECTED - will not be sent\")\n",
    "            return False, email_content\n",
    "        \n",
    "        else:\n",
    "            print(\"âš ï¸ Invalid choice. Please enter A, E, or R.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMTP Email Sending Function\n",
    "\n",
    "**âš ï¸ IMPORTANT**: This is a placeholder. Configure with your actual SMTP settings before production use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_email(email_content: EmailContent) -> bool:\n",
    "    \"\"\"\n",
    "    Send email via SMTP.\n",
    "    âš ï¸ Configure with your SMTP settings before production use!\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # EXAMPLE SMTP configuration (UPDATE THESE!)\n",
    "        SMTP_SERVER = \"smtp.gmail.com\"  # Change to your SMTP server\n",
    "        SMTP_PORT = 587\n",
    "        SMTP_USER = \"your-email@example.com\"  # Your email\n",
    "        SMTP_PASSWORD = \"your-app-password\"  # Your app password\n",
    "        \n",
    "        # Create message\n",
    "        msg = MIMEMultipart()\n",
    "        msg['From'] = SMTP_USER\n",
    "        msg['To'] = email_content.recipient\n",
    "        msg['Subject'] = email_content.subject\n",
    "        msg.attach(MIMEText(email_content.body, 'plain'))\n",
    "        \n",
    "        # Send email (COMMENTED OUT FOR SAFETY - ENABLE WHEN READY)\n",
    "        # server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)\n",
    "        # server.starttls()\n",
    "        # server.login(SMTP_USER, SMTP_PASSWORD)\n",
    "        # server.send_message(msg)\n",
    "        # server.quit()\n",
    "        \n",
    "        print(f\"ğŸ“§ Email sent successfully to {email_content.recipient}\")\n",
    "        return True\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to send email: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete Email Workflow\n",
    "\n",
    "Put it all together: Analysis â†’ Email Generation â†’ Human Review â†’ Send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main workflow with HITL\n",
    "config = {\"configurable\": {\"thread_id\": \"etf-final-v1\"}}\n",
    "companies = [\"Vanguard\", \"Fidelity\", \"State Street\", \"Charles Schwab\", \"Invesco\", \"Blackrock\"]\n",
    "recipient_email = \"investor@example.com\"  # Change to actual recipient\n",
    "\n",
    "print(\"ğŸ” TOP 3 ETFs ANALYSIS WITH EMAIL NOTIFICATION\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "all_results = []\n",
    "emails_sent = 0\n",
    "emails_rejected = 0\n",
    "\n",
    "for company in companies:\n",
    "    print(f\"\\nğŸ“Š Analyzing {company}...\")\n",
    "    \n",
    "    # Step 1: Get ETF analysis from agent\n",
    "    response = agent.invoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f\"Top 3 ETFs for {company}: ticker+1yr/5yr returns+revenue 2021-23+AUM\"\n",
    "                )\n",
    "            ]\n",
    "        },\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    analysis = response[\"structured_response\"]\n",
    "    tokens = token_counter(response[\"messages\"])\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_1.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_1.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_1.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_1.total_assets:7.1f}B\")\n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_2.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_2.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_2.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_2.total_assets:7.1f}B\")\n",
    "    print(f\"  ğŸ“ˆ {analysis.etf_3.etf_name:<6} | \"\n",
    "          f\"1yr:{analysis.etf_3.one_year_return:5.1f}% \"\n",
    "          f\"5yr:{analysis.etf_3.five_year_return:5.1f}% \"\n",
    "          f\"AUM:${analysis.etf_3.total_assets:7.1f}B\")\n",
    "    print(f\"  ğŸ“Š Tokens: ~{tokens} (msgs: {len(response['messages'])})\")\n",
    "    \n",
    "    all_results.append({\n",
    "        'company': analysis.company,\n",
    "        'etf1': analysis.etf_1.model_dump(),\n",
    "        'etf2': analysis.etf_2.model_dump(),\n",
    "        'etf3': analysis.etf_3.model_dump(),\n",
    "        'tokens': tokens\n",
    "    })\n",
    "    \n",
    "    # Step 2: Generate email content\n",
    "    email_content = generate_email_content(analysis, recipient_email)\n",
    "    \n",
    "    # Step 3: HUMAN-IN-THE-LOOP REVIEW\n",
    "    approved, reviewed_email = human_review_email(email_content)\n",
    "    \n",
    "    # Step 4: Send email if approved\n",
    "    if approved:\n",
    "        # Uncomment next line when SMTP is configured\n",
    "        # send_email(reviewed_email)\n",
    "        print(\"âš ï¸ SMTP not configured - email simulated\")\n",
    "        emails_sent += 1\n",
    "    else:\n",
    "        emails_rejected += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“Š FINAL SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"âœ… Companies Analyzed: {len(companies)}\")\n",
    "print(f\"ğŸ“§ Emails Sent: {emails_sent}\")\n",
    "print(f\"âŒ Emails Rejected: {emails_rejected}\")\n",
    "print(f\"ğŸ“Š Total ETFs Recommended: {len(companies) * 3}\")\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"ğŸ“Š ETF SUMMARY TABLE\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"{'Company'.ljust(13)}|{'ETF1'.ljust(8)}|{'1yr'.ljust(6)}|{'ETF2'.ljust(8)}|{'1yr'.ljust(6)}|{'ETF3'.ljust(8)}|{'Tokens'}\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for r in all_results:\n",
    "    e1, e2, e3 = r['etf1'], r['etf2'], r['etf3']\n",
    "    print(f\"{r['company'].ljust(13)}|{e1['etf_name'].ljust(8)}|{e1['one_year_return']:5.1f}%|\"\n",
    "          f\"{e2['etf_name'].ljust(8)}|{e2['one_year_return']:5.1f}%|\"\n",
    "          f\"{e3['etf_name'].ljust(8)}|{r['tokens']:5d}\")\n",
    "\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: Key Concepts Covered\n",
    "\n",
    "## 1. Structured Outputs\n",
    "- **TypedDict**: Lightweight type hints for simple structures\n",
    "- **Pydantic**: Full validation and rich features for production\n",
    "- **Nested Models**: Complex hierarchical data structures\n",
    "\n",
    "## 2. Agents and Tools\n",
    "- **Custom Tools**: Define functions LLMs can call\n",
    "- **Tool Binding**: Attach tools to models\n",
    "- **Structured Responses**: Ensure consistent output format\n",
    "\n",
    "## 3. Middleware\n",
    "- **SummarizationMiddleware**: Manage conversation context\n",
    "- **Token Counting**: Monitor and optimize costs\n",
    "- **Memory Management**: Preserve important context\n",
    "\n",
    "## 4. Human-in-the-Loop\n",
    "- **Review Workflows**: Human approval for critical operations\n",
    "- **Interactive Editing**: Modify AI outputs before execution\n",
    "- **Safety Gates**: Prevent errors in production\n",
    "\n",
    "## 5. Production Patterns\n",
    "- **Configuration Management**: Thread IDs for conversation tracking\n",
    "- **Error Handling**: Graceful fallbacks\n",
    "- **Data Export**: CSV, Pandas integration\n",
    "- **Email Integration**: SMTP configuration\n",
    "\n",
    "## Best Practices\n",
    "1. Always use structured outputs for production systems\n",
    "2. Implement token counting to manage costs\n",
    "3. Add human review for sensitive operations\n",
    "4. Use middleware for long conversations\n",
    "5. Validate all external inputs with Pydantic\n",
    "6. Keep system prompts clear and concise\n",
    "7. Test thoroughly before production deployment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
